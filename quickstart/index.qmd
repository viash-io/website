---
title: Welcome to Viash!
search: true
engine: knitr
---
  
{{< include ../_includes/_clone_template.qmd >}}


**Viash** is your go-to script wrapper for building data pipelines from modular software components. All you need is your trusty script and a metadata file to embark on this journey.

Check out some of Viash's key features:

- Code in your [favorite scripting language](/guide/component/create-component.html). Mix and match scripting  between multiple components to suit your needs. Viash supports a wide range of languages, including Bash, Python, R, Scala, JS, and C#.
- A **custom Docker container** is auto-generated based on the dependencies you've outlined in your metadata, meaning you don't need to be a Docker expert.
- Viash also generates a **Nextflow module** from your script, so no need to be a Nextflow guru either. 
- Effortlessly combine Nextflow modules to design and run scalable, reproducible data pipelines.
- Test every component on your local workstation using the convenient built-in development kit.



## Requirements

This guide assumes you've already installed [Viash](/installation), [Docker](https://docs.docker.com/get-docker) and [Nextflow](https://www.nextflow.io/index.html#GetStarted).


## Quickstart example project

To get up and running fast, we provide a [template project](https://github.com/viash-io/viash_project_template) for you to use. It contains three components from the same package as well as 2 custom operators from [vsh-pipeline-operators](https://viash-hub.com/data-intuitive/vsh-pipeline-operators), which are combined into a Nextflow pipeline as follows:

```{mermaid}
graph TD
   A(file?.tsv) --> X[vsh_flatten] 
   X --file1.tsv--> B1[/remove_comments/] --> C1[/take_column/] --> Y
   X --file2.tsv--> B2[/remove_comments/] --> C2[/take_column/] --> Y
   Y[vsh_toList] --> D[/combine_columns/]
   D --> E(output)
```

This pipeline takes one or more TSV files as input and stores its output in an output folder.

## Step 1: Get the template

First create a new repository by clicking the "Use this template" button. If you can't see the "Use this template" button, log into GitHub first.

Next, clone the repository using the following command.

```bash
git clone https://github.com/youruser/my_first_pipeline.git && cd my_first_pipeline
```


:::{.callout-note}
At the moment of writing, the branch to use should be 0_8_2.
:::

Your new repository should contain the following files:

```bash
tree my_first_pipeline
```

    .
    ├── CHANGELOG.md
    ├── LICENSE.md
    ├── README.md
    ├── README.qmd
    ├── _viash.yaml
    ├── main.nf
    ├── resources_test
    │   ├── file1.tsv
    │   └── file2.tsv
    └── src
        └── template
            ├── combine_columns
            │   ├── config.vsh.yaml
            │   └── script.R
            ├── remove_comments
            │   ├── config.vsh.yaml
            │   ├── script.sh
            │   └── test.sh
            ├── take_column
            │   ├── config.vsh.yaml
            │   └── script.py
            └── workflow
                ├── config.vsh.yaml
                ├── main.nf
                └── nextflow.config


## Step 2: Build the Viash components

With Viash you can turn the components in `src/` into Dockerized Nextflow modules by running:

```bash
viash ns build --setup cachedbuild --parallel
```
<details>
<summary>Output</summary>
```{bash echo=FALSE}
# First a temporary workaround to get this to build on a mac
mkdir -p target/dependencies/vsh/data-intuitive/vsh-pipeline-operators/v0.2.0/
viash ns build --setup cachedbuild --parallel
```
</details>

This command not only transforms the Viash components in `src/` to Nextflow modules but it also builds the containers when appropriate (starting from the Docker cache when available using the `cachedbuild` argument). Once everything is built, a new **target** directory has been created containing the executables and modules grouped per platform:

```bash
ls -l
```
<details>
<summary>Output</summary>
```{bash echo=FALSE}
ls -l
```
</details>

## Step 3: Run the pipeline

Now run the pipeline with Nextflow:

```bash
nextflow run . \
  -main-script template/workflow/main.nf \
  -with-docker \
  --input resources_test/file*.tsv \
  --publish_dir output
```

<details>
<summary>Output</summary>
```{bash echo=FALSE}
# avoid ansi log for proper static output using -ansi-log false
nextflow run . \
  -ansi-log false \
  -main-script target/nextflow/template/workflow/main.nf \
  -with-docker \
  --input resources_test/file*.tsv \
  --publish_dir output
```
</details>

This will run the different stages of the workflow , with the final result result being stored in a file named **run.combine_columns.output** in the output directory `output`:

```bash
cat output/run.combine_columns.output
```

<details>
<summary>Output</summary>
```{bash echo=FALSE}
cat output/run.combine_columns.output
```
</details>

## What's next?

Congratulations, you've reached the end of this quickstart tutorial, and we're excited for you to delve deeper into the world of Viash!
Our comprehensive [guide](/guide/) and [reference documentation](/reference/) is here to help you explore various topics, such as:

* [Creating a Viash component and converting it into a standalone executable](/guide/component/create-component.qmd)
* [Ensuring reproducibility and designing customised Docker images](/guide/component/add-dependencies.qmd)
* [Ensuring code reliability with unit testing for Viash](/guide/component/unit-testing.qmd)
* [Streamlining your workflow by performing batch operations on Viash projects](/guide/project/batch-processing.qmd)
* [Building Nextflow pipelines using Viash components](/guide/nextflow_vdsl3/index.qmd)

So, get ready to enhance your skills and create outstanding solutions with Viash!
